{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15c85f4-54fe-4e04-89c1-f2d6ccbdba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def other_paths(scene_id,base_path,base_depth_path,mode=\"train\") :\n",
    "    if not os.path.exists(os.path.join(base_depth_path, scene_id, 'dense0')):\n",
    "        os.mkdir(os.path.join(base_depth_path, scene_id, 'dense0'))\n",
    "    else :\n",
    "        shutil.rmtree(os.path.join(base_depth_path, scene_id, 'dense0'))\n",
    "        os.mkdir(os.path.join(base_depth_path, scene_id, 'dense0'))\n",
    "    if not os.path.exists(os.path.join(base_depth_path, scene_id, 'dense0','depths')):\n",
    "        os.mkdir(os.path.join(base_depth_path, scene_id, 'dense0','depths'))\n",
    "    if not os.path.exists(os.path.join(base_depth_path, scene_id, 'dense0','calib')):\n",
    "        os.mkdir(os.path.join(base_depth_path, scene_id, 'dense0','calib'))\n",
    "    base_undistorted_sfm_path = os.path.join(\n",
    "        base_path, 'data',mode\n",
    "    )\n",
    "    # print(\"base_undistorted_sfm_path - \",base_undistorted_sfm_path)\n",
    "    undistorted_sparse_path = os.path.join(\n",
    "        base_undistorted_sfm_path, scene_id, 'sfm'\n",
    "    )\n",
    "    # print(\"undistorted_sparse_path - \",undistorted_sparse_path)\n",
    "    depths_path = os.path.join(\n",
    "        base_depth_path, scene_id, 'dense0', 'depths'\n",
    "    )\n",
    "    \n",
    "    images_path = os.path.join(\n",
    "        base_undistorted_sfm_path, scene_id, 'images'\n",
    "    )\n",
    "    \n",
    "    return base_undistorted_sfm_path,undistorted_sparse_path,depths_path,images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3250cf4-047b-45dc-b207-428ccd60faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_changes() :\n",
    "    if os.path.exists(\"/home/hemant/Downloads/amit/ALIKE_code/data/train/multi-temporal-temple-baalshamin/images/2015_10_15_19.png\"):\n",
    "        os.rename(\"/home/hemant/Downloads/amit/ALIKE_code/data/train/multi-temporal-temple-baalshamin/images/2015_10_15_19.png\",\"/home/hemant/Downloads/amit/ALIKE_code/data/train/multi-temporal-temple-baalshamin/images/2015_10_15_19.12.50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2598821a-34bd-4519-855d-a307e631fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images.txt\n",
    "def check_images_exist(undistorted_sparse_path,images_path) :\n",
    "    with open(os.path.join(undistorted_sparse_path, 'images.txt'), 'r') as f:\n",
    "        raw = f.readlines()[4 :]  # skip the header\n",
    "    \n",
    "    image_names = []\n",
    "\n",
    "    for idx, (image, points) in enumerate(zip(raw[:: 2], raw[1 :: 2])):\n",
    "        image = image.split(' ')\n",
    "    \n",
    "        image_name = image[-1].strip('\\n').lower().replace(\"-\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"_\").replace(\"__\",\"_\")\n",
    "        if os.path.exists(os.path.join(images_path, image_name)):\n",
    "            image_names.append(image_name)\n",
    "        else :\n",
    "            if image_name.endswith(\".png\") :\n",
    "                find_image_name = image_name.replace(\".png\",\".jpg\")\n",
    "            elif image_name.endswith(\".jpg\") :\n",
    "                find_image_name = image_name.replace(\".jpg\",\".png\")\n",
    "\n",
    "            if not os.path.exists(os.path.join(images_path, find_image_name)):\n",
    "                print(\"{} not found . Converting from {} . This also not found\".format(image_name,find_image_name))\n",
    "\n",
    "            else :\n",
    "                #open image in png format \n",
    "                img_png = Image.open(os.path.join(images_path, find_image_name))\n",
    "                if img_png.mode in (\"RGBA\", \"P\"): \n",
    "                    img_png = img_png.convert(\"RGB\")\n",
    "                  \n",
    "                #The image object is used to save the image in jpg format \n",
    "                img_png.save(os.path.join(images_path, image_name))\n",
    "                os.remove(os.path.join(images_path, find_image_name))\n",
    "                image_names.append(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faccd90d-6aae-48de-9c05-8cb4fd252e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from PIL import Image\n",
    "import torch\n",
    "from LightGlue.lightglue import ALIKED\n",
    "import kornia as K\n",
    "\n",
    "def load_torch_image(fname, device=torch.device('cpu')):\n",
    "    img = K.io.load_image(fname, K.io.ImageLoadType.RGB32, device=device)[None, ...]\n",
    "    return img\n",
    "\n",
    "def depth_file_create(images_path,depths_path) :\n",
    "\n",
    "    image_list = [image_path for image_path in os.listdir(images_path) if ( image_path.endswith(\".png\") or image_path.endswith(\".jpg\") )]\n",
    "\n",
    "    num_features = 4096\n",
    "    resize_to = 1024\n",
    "    device=torch.device('cuda')\n",
    "    dtype = torch.float32 # ALIKED has issues with float16\n",
    "    extractor = ALIKED(max_num_keypoints=num_features, detection_threshold=0.01, resize=resize_to).eval().to(device, dtype)\n",
    "    \n",
    "    for image in image_list :\n",
    "        if image.endswith(\".png\") :\n",
    "            save_path = os.path.join(depths_path, image.replace(\".png\",\".h5\"))\n",
    "        else :\n",
    "            save_path = os.path.join(depths_path, image.replace(\".jpg\",\".h5\"))\n",
    "        img_path = os.path.join(images_path, image)\n",
    "        \n",
    "        # print('image size: %d bytes'%os.path.getsize(img_path))\n",
    "        image0 = load_torch_image(img_path, device=device).to(dtype)\n",
    "        feats0 = extractor.extract_dense_map(image0)  # auto-resize the image, disable with resize=None\n",
    "        feats0[1][0,0,:,:]\n",
    "        hf = h5py.File(save_path, 'a') # open a hdf5 file\n",
    "        # img_np = np.array(Image.open(img_path))\n",
    "        dense_data = feats0[1][0,0,:,:].detach().cpu()\n",
    "        \n",
    "        dset = hf.create_dataset('depth', data=dense_data)  # write the data to hdf5 file\n",
    "        hf.close()  # close the hdf5 file\n",
    "        del feats0,dense_data\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # print('hdf5 file size: %d bytes'%os.path.getsize(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f23951-367d-482c-b084-680f377117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process cameras.txt\n",
    "def process_cameras(undistorted_sparse_path) :\n",
    "    with open(os.path.join(undistorted_sparse_path, 'cameras.txt'), 'r') as f:\n",
    "        raw = f.readlines()[3 :]  # skip the header\n",
    "    \n",
    "    camera_intrinsics = {}\n",
    "    for camera in raw:\n",
    "        camera = camera.split(' ')\n",
    "        camera_intrinsics[int(camera[0])] = [float(elem) for elem in camera[2 :]]\n",
    "    \n",
    "    return camera_intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99b56ed-721c-4ba7-a522-7df6a3846dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process points3D.txt\n",
    "def process_points3D(undistorted_sparse_path) :\n",
    "    with open(os.path.join(undistorted_sparse_path, 'points3D.txt'), 'r') as f:\n",
    "        raw = f.readlines()[3 :]  # skip the header\n",
    "    \n",
    "    points3D = {}\n",
    "    for point3D in raw:\n",
    "        point3D = point3D.split(' ')\n",
    "        points3D[int(point3D[0])] = np.array([\n",
    "            float(point3D[1]), float(point3D[2]), float(point3D[3])\n",
    "        ])\n",
    "    \n",
    "    return points3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e880820e-6b4b-4cc6-b4c7-38ed6d7dc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images.txt\n",
    "def process_images(undistorted_sparse_path,images_path) :\n",
    "    with open(os.path.join(undistorted_sparse_path, 'images.txt'), 'r') as f:\n",
    "        raw = f.readlines()[4 :]  # skip the header\n",
    "    \n",
    "    image_id_to_idx = {}\n",
    "    image_names = []\n",
    "    raw_pose = []\n",
    "    camera = []\n",
    "    points3D_id_to_2D = []\n",
    "    n_points3D = []\n",
    "    for idx, (image, points) in enumerate(zip(raw[:: 2], raw[1 :: 2])):\n",
    "        image = image.split(' ')\n",
    "        points = points.split(' ')\n",
    "    \n",
    "        image_id_to_idx[int(image[0])] = idx\n",
    "    \n",
    "        image_name = image[-1].strip('\\n').lower().replace(\"-\",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"_\").replace(\"__\",\"_\")\n",
    "\n",
    "        if os.path.exists(os.path.join(images_path, image_name)) :\n",
    "            image_names.append(image_name)\n",
    "        \n",
    "            raw_pose.append([float(elem) for elem in image[1 : -2]])\n",
    "            camera.append(int(image[-2]))\n",
    "            current_points3D_id_to_2D = {}\n",
    "            for x, y, point3D_id in zip(points[:: 3], points[1 :: 3], points[2 :: 3]):\n",
    "                if int(point3D_id) == -1:\n",
    "                    continue\n",
    "                current_points3D_id_to_2D[int(point3D_id)] = [float(x), float(y)]\n",
    "            points3D_id_to_2D.append(current_points3D_id_to_2D)\n",
    "            n_points3D.append(len(current_points3D_id_to_2D))\n",
    "    return image_id_to_idx,image_names,raw_pose,camera,points3D_id_to_2D,n_points3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bac4392-b705-42e6-b6c0-a632b0fa5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and depthmaps paths\n",
    "def image_depthmaps_path(image_names,images_path,depths_path):\n",
    "    image_paths = []\n",
    "    depth_paths = []\n",
    "    for image_name in image_names:\n",
    "        image_path = os.path.join(images_path, image_name)\n",
    "       \n",
    "        # Path to the depth file\n",
    "        depth_path = os.path.join(\n",
    "            depths_path, '%s.h5' % os.path.splitext(image_name)[0]\n",
    "        )\n",
    "        \n",
    "        if os.path.exists(depth_path):\n",
    "            # Check if depth map or background / foreground mask\n",
    "            file_size = os.stat(depth_path).st_size\n",
    "            # Rough estimate - 75KB might work as well\n",
    "            if file_size < 100 * 1024:\n",
    "                depth_paths.append(None)\n",
    "                image_paths.append(None)\n",
    "            else:\n",
    "                depth_paths.append(depth_path[len(base_path) + 1 :])\n",
    "                image_paths.append(image_path[len(base_path) + 1 :])\n",
    "        else:\n",
    "            depth_paths.append(None)\n",
    "            image_paths.append(None)\n",
    "    \n",
    "    return image_paths,depth_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f71257-9950-4e2a-a446-361f92816603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera configuration\n",
    "def camera_configuration(image_names,image_paths,camera_intrinsics,camera,raw_pose,points3D_id_to_2D,points3D):\n",
    "    intrinsics = []\n",
    "    poses = []\n",
    "    principal_axis = []\n",
    "    points3D_id_to_ndepth = []\n",
    "    for idx, image_name in enumerate(image_names):\n",
    "        if image_paths[idx] is None:\n",
    "            intrinsics.append(None)\n",
    "            poses.append(None)\n",
    "            principal_axis.append([0, 0, 0])\n",
    "            points3D_id_to_ndepth.append({})\n",
    "            continue\n",
    "    \n",
    "        image_intrinsics = camera_intrinsics[camera[idx]]\n",
    "        K = np.zeros([3, 3])\n",
    "        K[0, 0] = image_intrinsics[0]\n",
    "        K[0, 2] = image_intrinsics[3]\n",
    "        K[1, 1] = image_intrinsics[1]\n",
    "        K[1, 2] = image_intrinsics[4]\n",
    "        K[2, 2] = 1\n",
    "        intrinsics.append(K)\n",
    "    \n",
    "        image_pose = raw_pose[idx]\n",
    "        qvec = image_pose[: 4]\n",
    "        qvec = qvec / np.linalg.norm(qvec)\n",
    "        w, x, y, z = qvec\n",
    "        R = np.array([\n",
    "            [\n",
    "                1 - 2 * y * y - 2 * z * z,\n",
    "                2 * x * y - 2 * z * w,\n",
    "                2 * x * z + 2 * y * w\n",
    "            ],\n",
    "            [\n",
    "                2 * x * y + 2 * z * w,\n",
    "                1 - 2 * x * x - 2 * z * z,\n",
    "                2 * y * z - 2 * x * w\n",
    "            ],\n",
    "            [\n",
    "                2 * x * z - 2 * y * w,\n",
    "                2 * y * z + 2 * x * w,\n",
    "                1 - 2 * x * x - 2 * y * y\n",
    "            ]\n",
    "        ])\n",
    "        principal_axis.append(R[2, :])\n",
    "        t = image_pose[4 : 7]\n",
    "        # World-to-Camera pose\n",
    "        current_pose = np.zeros([4, 4])\n",
    "        current_pose[: 3, : 3] = R\n",
    "        current_pose[: 3, 3] = t\n",
    "        current_pose[3, 3] = 1\n",
    "        # Camera-to-World pose\n",
    "        # pose = np.zeros([4, 4])\n",
    "        # pose[: 3, : 3] = np.transpose(R)\n",
    "        # pose[: 3, 3] = -np.matmul(np.transpose(R), t)\n",
    "        # pose[3, 3] = 1\n",
    "        poses.append(current_pose)\n",
    "        if image_paths[idx].endswith(\".jpg\") :\n",
    "            save_path = image_paths[idx].replace(\"images\",\"dense0/calib\").replace(\".jpg\",\".h5\")\n",
    "        elif image_paths[idx].endswith(\".png\") :\n",
    "            save_path = image_paths[idx].replace(\"images\",\"dense0/calib\").replace(\".png\",\".h5\")\n",
    "        if os.path.exists(save_path) :\n",
    "            os.remove(save_path)\n",
    "        hf = h5py.File(save_path, 'a') # open a hdf5 file\n",
    "        # img_np = np.array(Image.open(img_path))\n",
    "        data={}\n",
    "        data[\"K\"]=K\n",
    "        data[\"R\"]=R\n",
    "        data[\"T\"]=t\n",
    "        \n",
    "        dset = hf.create_dataset('K', data=data[\"K\"])  # write the data to hdf5 file\n",
    "        dset = hf.create_dataset('R', data=data[\"R\"])  # write the data to hdf5 file\n",
    "        dset = hf.create_dataset('T', data=data[\"T\"])  # write the data to hdf5 file\n",
    "        hf.close()\n",
    "        \n",
    "        current_points3D_id_to_ndepth = {}\n",
    "        for point3D_id in points3D_id_to_2D[idx].keys():\n",
    "            p3d = points3D[point3D_id]\n",
    "            current_points3D_id_to_ndepth[point3D_id] = (np.dot(R[2, :], p3d) + t[2]) / (.5 * (K[0, 0] + K[1, 1])) \n",
    "        points3D_id_to_ndepth.append(current_points3D_id_to_ndepth)\n",
    "    principal_axis = np.array(principal_axis)\n",
    "    angles = np.rad2deg(np.arccos(\n",
    "        np.clip(\n",
    "            np.dot(principal_axis, np.transpose(principal_axis)),\n",
    "            -1, 1\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    return intrinsics,poses,principal_axis,points3D_id_to_ndepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c7f2cf-274f-4005-9f9c-5daabdca1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overlap score\n",
    "def compute_overlap_score(n_images,image_paths,depth_paths,points3D_id_to_2D,points3D_id_to_ndepth):\n",
    "    overlap_matrix = np.full([n_images, n_images], -1.)\n",
    "    scale_ratio_matrix = np.full([n_images, n_images], -1.)\n",
    "    for idx1 in range(n_images):\n",
    "        if image_paths[idx1] is None or depth_paths[idx1] is None:\n",
    "            continue\n",
    "        for idx2 in range(idx1 + 1, n_images):\n",
    "            if image_paths[idx2] is None or depth_paths[idx2] is None:\n",
    "                continue\n",
    "            matches = (\n",
    "                points3D_id_to_2D[idx1].keys() &\n",
    "                points3D_id_to_2D[idx2].keys()\n",
    "            )\n",
    "            min_num_points3D = min(\n",
    "                len(points3D_id_to_2D[idx1]), len(points3D_id_to_2D[idx2])\n",
    "            )\n",
    "            overlap_matrix[idx1, idx2] = len(matches) / len(points3D_id_to_2D[idx1])  # min_num_points3D\n",
    "            overlap_matrix[idx2, idx1] = len(matches) / len(points3D_id_to_2D[idx2])  # min_num_points3D\n",
    "            if len(matches) == 0:\n",
    "                continue\n",
    "            points3D_id_to_ndepth1 = points3D_id_to_ndepth[idx1]\n",
    "            points3D_id_to_ndepth2 = points3D_id_to_ndepth[idx2]\n",
    "            nd1 = np.array([points3D_id_to_ndepth1[match] for match in matches])\n",
    "            nd2 = np.array([points3D_id_to_ndepth2[match] for match in matches])\n",
    "            min_scale_ratio = np.min(np.maximum(nd1 / nd2, nd2 / nd1))\n",
    "            scale_ratio_matrix[idx1, idx2] = min_scale_ratio\n",
    "            scale_ratio_matrix[idx2, idx1] = min_scale_ratio\n",
    "\n",
    "    return overlap_matrix,scale_ratio_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17f430a-495c-46a7-aa5b-d89099ae928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def creating_dataset(base_path,mode) :\n",
    "    \n",
    "    base_depth_path = os.path.join(\n",
    "        base_path, 'data',mode\n",
    "    )\n",
    "    print(\"base_depth_path - \",base_depth_path)\n",
    "    print(\"-\"*117)\n",
    "    scene_list = [directory for directory in os.listdir(base_depth_path) if os.path.isdir(os.path.join(base_depth_path,directory))]\n",
    "    \n",
    "    train_json_data = {}\n",
    "    val_json_data = {}\n",
    "    \n",
    "    for scene in scene_list :\n",
    "        print(\"scene_id - \",scene)\n",
    "        print(f\"GPU total used memory is {round(get_used_gpu_memory()[0]/1024,2)} GB\")\n",
    "        scene_id = scene\n",
    "\n",
    "        base_undistorted_sfm_path,undistorted_sparse_path,depths_path,images_path = other_paths(scene_id,base_path,base_depth_path,mode)\n",
    "        check_images_exist(undistorted_sparse_path,images_path)\n",
    "        depth_file_create(images_path,depths_path)\n",
    "        camera_intrinsics = process_cameras(undistorted_sparse_path)\n",
    "        points3D = process_points3D(undistorted_sparse_path)\n",
    "        image_id_to_idx,image_names,raw_pose,camera,points3D_id_to_2D,n_points3D = process_images(undistorted_sparse_path,images_path)\n",
    "        image_paths,depth_paths = image_depthmaps_path(image_names,images_path,depths_path)\n",
    "        intrinsics,poses,principal_axis,points3D_id_to_ndepth = camera_configuration(image_names,image_paths,camera_intrinsics,camera,raw_pose,points3D_id_to_2D,points3D)\n",
    "        overlap_matrix,scale_ratio_matrix = compute_overlap_score(len(image_names),image_paths,depth_paths,points3D_id_to_2D,points3D_id_to_ndepth)\n",
    "\n",
    "        if scene_id == \"pond\" :\n",
    "            train_image_names = image_names[:1001]\n",
    "            val_image_names = image_names[1001:]\n",
    "\n",
    "            val_json_data[scene_id]={\n",
    "                'image_path':images_path,\n",
    "                'images':val_image_names,#[image.split(\"/\")[-1].replace(\"jpg\",\"png\") for image in image_paths],\n",
    "                'depth_path':depths_path,\n",
    "                'calib_path':depths_path.replace(\"depths\",\"calib\"),\n",
    "                'tuples':list(range(len(val_image_names))),#[int(image.split(\".\")[0].split(\"/\")[-1]) for image in image_paths],#list(range(len(image_paths))),\n",
    "            }\n",
    "        else:\n",
    "            train_image_names = image_names\n",
    "        \n",
    "        train_json_data[scene_id]={\n",
    "            'image_path':images_path,\n",
    "            'images':train_image_names,#[image.split(\"/\")[-1].replace(\"jpg\",\"png\") for image in image_paths],\n",
    "            'depth_path':depths_path,\n",
    "            'calib_path':depths_path.replace(\"depths\",\"calib\"),\n",
    "            'tuples':list(range(len(train_image_names))),#[int(image.split(\".\")[0].split(\"/\")[-1]) for image in image_paths],#list(range(len(image_paths))),\n",
    "        }\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"-\"*117)\n",
    "    return train_json_data,val_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e4a074f-bdad-45f1-81ad-2c6e3c8d8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffe1454-c9eb-4b7a-80c0-1da939e54227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_total_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.total --format=csv\"\n",
    "    memory_total_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_total_values = [int(x.split()[0]) for i, x in enumerate(memory_total_info)]\n",
    "    return memory_total_values\n",
    "\n",
    "def get_free_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "def get_used_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.used --format=csv\"\n",
    "    memory_used_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_used_values = [int(x.split()[0]) for i, x in enumerate(memory_used_info)]\n",
    "    return memory_used_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ca3b9d6-1893-4229-985b-313f3119af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n",
      "GPU total memory      is 48.0 GB\n",
      "GPU total used memory is 0.72 GB\n",
      "base_path -  /home/hemant/Downloads/amit/ALIKE_code\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "mode -  train\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "base_depth_path -  /home/hemant/Downloads/amit/ALIKE_code/data/train\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  multi-temporal-temple-baalshamin\n",
      "GPU total used memory is 0.72 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  dioscuri\n",
      "GPU total used memory is 1.06 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  pond\n",
      "GPU total used memory is 1.06 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  church\n",
      "GPU total used memory is 0.34 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  lizard\n",
      "GPU total used memory is 0.34 GB\n",
      "00584.jpg not found . Converting from 00584.png . This also not found\n",
      "00583.jpg not found . Converting from 00583.png . This also not found\n",
      "00579.jpg not found . Converting from 00579.png . This also not found\n",
      "00578.jpg not found . Converting from 00578.png . This also not found\n",
      "00576.jpg not found . Converting from 00576.png . This also not found\n",
      "00575.jpg not found . Converting from 00575.png . This also not found\n",
      "00574.jpg not found . Converting from 00574.png . This also not found\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  transp_obj_glass_cup\n",
      "GPU total used memory is 0.34 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "scene_id -  transp_obj_glass_cylinder\n",
      "GPU total used memory is 0.34 GB\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "GPU total used memory is 0.34 GB\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(f\"GPU total memory      is {round(get_total_gpu_memory()[0]/1024,2)} GB\")\n",
    "print(f\"GPU total used memory is {round(get_used_gpu_memory()[0]/1024,2)} GB\")\n",
    "base_path = os.getcwd()\n",
    "# Remove the trailing / if need be.\n",
    "\n",
    "other_changes()\n",
    "\n",
    "if base_path[-1] in ['/', '\\\\']:\n",
    "    base_path = base_path[: - 1]\n",
    "print(\"base_path - \",base_path)\n",
    "print(\"-\"*117)\n",
    "mode = \"train\"\n",
    "print(\"mode - \",mode)\n",
    "print(\"-\"*117)\n",
    "train_json_data , val_json_data = creating_dataset(base_path,mode)\n",
    "\n",
    "with open(os.path.join(base_path,\"data\",\"megadepth\",\"dataset.json\"), \"w\") as file:\n",
    "    json.dump(train_json_data, file,cls=NumpyEncoder)\n",
    "\n",
    "# mode = \"val\"\n",
    "# print(\"mode - \",mode)\n",
    "# print(\"-\"*117)\n",
    "# json_data = creating_dataset(base_path,mode)\n",
    "\n",
    "with open(os.path.join(base_path,\"data\",\"imw2020val\",\"dataset.json\"), \"w\") as file:\n",
    "    json.dump(val_json_data, file,cls=NumpyEncoder)\n",
    "\n",
    "print(f\"GPU total used memory is {round(get_used_gpu_memory()[0]/1024,2)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0f4bcd0-8414-45b1-9ee6-02f970c8c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"val\"\n",
    "# print(\"mode - \",mode)\n",
    "# print(\"-\"*117)\n",
    "# json_data = creating_dataset(base_path,mode)\n",
    "\n",
    "# with open(os.path.join(base_path,\"data\",\"imw2020val\",\"dataset.json\"), \"w\") as file:\n",
    "#     json.dump(json_data, file,cls=NumpyEncoder)\n",
    "\n",
    "# print(f\"GPU total used memory is {round(get_used_gpu_memory()[0]/1024,2)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d780cd58-cadb-41db-8e53-ba5f191d6f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.0\n",
      "38.88671875\n",
      "38.88671875\n",
      "---------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(get_total_gpu_memory()[0]/1024)\n",
    "print(get_used_gpu_memory()[0]/1024)\n",
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(get_used_gpu_memory()[0]/1024)\n",
    "print(\"-\"*117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85b43ab4-c7de-431d-a762-7a7168ecabad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"/home/hemant/Downloads/amit/ALIKE_code/data/train/multi-temporal-temple-baalshamin/images/070313_img_6187_syria_palmyra_roman_ruins_999x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0992f-d4cc-45ea-89a4-b5d7031e92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "070313_img_6187_syria_palmyra_roman_ruins_999x\n",
    "070313_img_6187_syria-palmyra-roman-ruins_999x.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d63df98-5bc1-4ba1-8cc6-4b5c139c5dc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intrinsics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mintrinsics\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(poses[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      3\u001b[0m cal_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/hemant/Downloads/amit/ALIKE_code/data/train/church/dense0/depths/test.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intrinsics' is not defined"
     ]
    }
   ],
   "source": [
    "print(intrinsics[0])\n",
    "print(poses[0])\n",
    "cal_path = \"/home/hemant/Downloads/amit/ALIKE_code/data/train/church/dense0/depths/test.h5\"\n",
    "with h5py.File(cal_path, 'r') as f:\n",
    "    print(\"f - \",f.keys())\n",
    "    intrinsic = f['K'][()]\n",
    "    print(\"intrinsic - \",intrinsic)\n",
    "    pose[:3, :3] = f['R'][()]\n",
    "    pose[:3, 3] = f['T'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75b51515-657b-47aa-a88d-6ca92c847096",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/hemant/Downloads/amit/ALIKE_code/data/train/church/dense0/depths/test.h5\"\n",
    "# img_path = os.path.join(images_path, image)\n",
    "# print('image size: %d bytes'%os.path.getsize(img_path))\n",
    "hf = h5py.File(save_path, 'a') # open a hdf5 file\n",
    "# img_np = np.array(Image.open(img_path))\n",
    "data={}\n",
    "data[\"K\"]=intrinsics[0]\n",
    "data[\"R\"]=poses[0][:3, :3]\n",
    "data[\"T\"]=poses[0][:3, 3]\n",
    "\n",
    "dset = hf.create_dataset('K', data=data[\"K\"])  # write the data to hdf5 file\n",
    "dset = hf.create_dataset('R', data=data[\"R\"])  # write the data to hdf5 file\n",
    "dset = hf.create_dataset('T', data=data[\"T\"])  # write the data to hdf5 file\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "beb1df20-9ac1-449d-b98b-4a02f3743102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['SfM_features']>\n",
      "(5, 820)\n"
     ]
    }
   ],
   "source": [
    "d_path = \"/home/hemant/Downloads/amit/ALIKE_code/3064466540_f66ed4d28d_o.jpg.h5\"\n",
    "hdf5_file_read = h5py.File(d_path,'r')\n",
    "print(hdf5_file_read.keys())\n",
    "gt_depth = hdf5_file_read.get('/SfM_features')\n",
    "gt_depth = np.array(gt_depth)\n",
    "print(gt_depth.shape)\n",
    "hdf5_file_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7374e050-0901-47cd-b1bf-7a5b83d0bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "d = list(range(100))\n",
    "print(d.remove(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cce7abc7-c1a3-484c-a792-1a398876dfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "imgL = cv2.imread('/home/hemant/Downloads/amit/ALIKE_code/data/train/church/images/00001.jpg',0)\n",
    "imgR = cv2.imread('/home/hemant/Downloads/amit/ALIKE_code/data/train/church/images/00001.jpg',0)\n",
    "\n",
    "stereo = cv2.StereoBM_create(numDisparities=96, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "disparity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d77b3144-21cf-4821-a21a-6f509093a1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgL[imgL != imgR].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6fcbb229-588e-49f9-81a4-789677b40375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786432"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3afee3-6c1c-4418-8d3c-845c8867efb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
